# Google Maps Business Scraper & Dashboard

A production-ready system for scraping business information from Google Maps with a modern web dashboard interface. Deployed on AWS Lambda with MongoDB backend.

## ğŸš€ Live Demo

**Production URL**: You will get it after deploying to AWS Lambda using the instructions below.

## âœ¨ Features

### Web Dashboard
- ğŸ“Š **Real-time scraping progress** - Live activity tracking during scraping
- ğŸ” **Search & filter** businesses by name, category, or location
- ğŸ“ˆ **Statistics** - Total businesses, average ratings, top categories
- âœï¸ **CRUD operations** - Edit, delete, and manage scraped data
- ğŸ“¥ **Export to CSV** - Download business data for analysis
- ğŸŒ **MongoDB integration** - Persistent cloud storage

### Scraping Engine
- ğŸ—ºï¸ **Google Maps automation** - Playwright-based scraping
- ğŸ“± **Comprehensive data extraction**:
  - Business name, phone, website, address
  - Instagram and WhatsApp (including from Reserve/Order buttons)
  - Ratings and review counts
  - Geographic coordinates
- ğŸ¯ **Smart duplicate detection** - Name, phone, and URL matching
- ğŸ’¾ **Immediate database saves** - No data loss on errors
- ğŸ›¡ï¸ **Robust error handling** - Graceful recovery and retry logic

### AWS Lambda Deployment
- âš¡ **Serverless architecture** - No server management
- ğŸ³ **Dockerized** - Consistent environments
- ğŸ”„ **Async invocation** - No API Gateway timeouts
- ğŸ“Š **CloudWatch logging** - Full observability
- ğŸŒ **API Gateway** - RESTful endpoint with `/prod` stage

## ğŸ“‹ What's Working

| Component | Status | Description |
|-----------|--------|-------------|
| Web Dashboard | âœ… Working | Flask app with modern UI |
| MongoDB Integration | âœ… Working | External MongoDB @ easypanel.host |
| Google Maps Scraper | âœ… Working | 100% success rate (fixed Oct 22) |
| WhatsApp Extraction | âœ… Enhanced | Extracts from action buttons |
| Lambda Deployment | âœ… Working | 1024MB, 300s timeout |
| Async Scraping | âœ… Working | Self-invocation pattern |
| Real-time Progress | âœ… Working | Live activity updates |
| Error Handling | âœ… Production-ready | Graceful degradation |
| Database Errors | âœ… User-friendly | Clean messages |

## ğŸ“ Project Structure

```
scraper_playwright/
â”œâ”€â”€ app.py                    # Main Flask application
â”œâ”€â”€ scrape_businesses_maps.py # Google Maps scraper
â”œâ”€â”€ database.py               # MongoDB operations
â”œâ”€â”€ lambda_handler.py         # AWS Lambda entry point
â”œâ”€â”€ extract_contact_info.py   # Contact extraction (deprecated in scraping flow)
â”œâ”€â”€ json_database.py          # Fallback JSON storage
â”œâ”€â”€ templates/                # Jinja2 templates
â”‚   â”œâ”€â”€ index.html           # Scraping interface
â”‚   â””â”€â”€ dashboard.html       # Business management
â”œâ”€â”€ static/                   # CSS, JS, images
â”œâ”€â”€ infra/                    # Terraform configuration
â”‚   â”œâ”€â”€ main.tf
â”‚   â”œâ”€â”€ terraform.tfvars
â”‚   â””â”€â”€ outputs.tf
â”œâ”€â”€ Dockerfile               # Lambda container image
â”œâ”€â”€ deploy.sh                # Deployment automation
â””â”€â”€ requirements.txt         # Python dependencies
```

## ğŸ”§ Data Structure

Each scraped business contains:

```json
{
  "name": "Business Name",
  "phone": "011 1234-5678",
  "website": "https://example.com",
  "email": null,
  "address": "Street Address, City",
  "rating": "4.8",
  "reviews": 152,
  "instagram": "https://instagram.com/username",
  "whatsapp": "+5491123456789",
  "scraped_at": "2025-10-22T12:34:56.789000",
  "search_query": "plomero, caba"
}
```

## ğŸš€ Quick Start

### Local Development

1. **Clone and install**:
```bash
git clone https://github.com/cf2018/scraper_playwright.git
cd scraper_playwright
python3 -m venv venv
source venv/bin/activate
pip install -r requirements.txt
playwright install chromium
```

2. **Set environment variables**:
```bash
cp .env.example .env
# Edit .env with your MongoDB credentials
```

3. **Run locally**:
```bash
python app.py
# Dashboard: http://localhost:5000/
```

### Command-Line Scraping

```bash
# Scrape specific business type and location
python scrape_businesses_maps.py "plomero, caba" --max-results 10

# Output saved to: json_output/plomero_caba_YYYYMMDD_HHMMSS.json
```

### AWS Lambda Deployment

1. **Configure AWS credentials**:
```bash
aws configure
```

2. **Set MongoDB credentials** in `infra/terraform.tfvars`:
```hcl
mongodb_connection_string = "mongodb://user:pass@host:27017/scraper"
mongodb_database_name = "scraper"
```

3. **Deploy**:
```bash
./deploy.sh deploy
```

4. **Access**:
- Dashboard: `https://<api-id>.execute-api.us-east-1.amazonaws.com/prod/`

## ğŸ“Š Usage Examples

### Scrape via Web Interface

1. Navigate to `/` (scraping page)
2. Enter search query (e.g., "restaurants, new york")
3. Set max results (default: 20, Lambda max: 20)
4. Click "Start Scraping"
5. Watch live progress updates
6. View results in `/dashboard`

### Scrape via API

```bash
# Start scraping
curl -X POST https://your-api.amazonaws.com/prod/api/scrape \
  -H "Content-Type: application/json" \
  -d '{"search_query": "plomero, caba", "max_results": 10}'

# Check status
curl https://your-api.amazonaws.com/prod/api/scraping-status/<task_id>

# Get businesses
curl https://your-api.amazonaws.com/prod/api/businesses
```

## ğŸ”’ Environment Variables

| Variable | Description | Required |
|----------|-------------|----------|
| `MONGODB_CONNECTION_STRING` | MongoDB URI | Yes |
| `MONGODB_DATABASE_NAME` | Database name | Yes |
| `LAMBDA_ENVIRONMENT` | Set to `true` in Lambda | Auto |
| `API_PREFIX` | API Gateway stage prefix | Auto |

## ğŸ§ª Recent Improvements (Oct 22, 2025)

### Fixed Critical Browser Stability Issue âœ…
- **Problem**: Scraper crashed after first business (browser context closed)
- **Solution**: Disabled website contact extraction during multi-business scraping
- **Result**: 100% success rate (was 10%)

### Enhanced WhatsApp Extraction âœ…
- Extracts WhatsApp from Reserve/Order buttons with `wa.me` links
- Handles URL-encoded parameters
- Validates phone number format (10-15 digits)

### Improved Browser Fingerprinting âœ…
- Updated to Chrome 131 user agent
- Argentine locale (`es-AR`) and timezone
- Buenos Aires geolocation coordinates
- Proper Sec-Fetch-* headers

### Robust Error Recovery âœ…
- Page validity checking before navigation
- Fallback to re-navigate on errors
- Graceful exit on unrecoverable failures

## ğŸ› Known Limitations

- **Email extraction**: Disabled to maintain stability (was ~40% coverage)
- **Lambda max results**: Limited to 20 businesses due to 300s timeout
- **Website extraction**: Disabled in multi-business scraping (stability over completeness)

## ğŸ“š Documentation

- [Lambda Deployment Guide](LAMBDA_DEPLOYMENT.md)
- [Stability Improvements](SCRAPER_STABILITY_IMPROVEMENTS.md)
- [WhatsApp Extraction](WHATSAPP_EXTRACTION_IMPROVEMENTS.md)

## ğŸ”— Technology Stack

- **Backend**: Python 3.12, Flask 3.1.2
- **Scraping**: Playwright (Chromium)
- **Database**: MongoDB (external cloud)
- **Deployment**: AWS Lambda, API Gateway, ECR
- **IaC**: Terraform
- **Frontend**: Vanilla JS, Tailwind-inspired CSS

## ğŸ“ˆ Performance

- **Scraping speed**: ~3-5 seconds per business
- **Lambda cold start**: ~2-3 seconds
- **Lambda warm execution**: ~1 second for dashboard
- **Database queries**: <100ms average
- **Success rate**: 100% (after stability fixes)

## ğŸ¤ Contributing

1. Fork the repository
2. Create a feature branch (`git checkout -b feature/amazing-feature`)
3. Commit changes (`git commit -m 'Add amazing feature'`)
4. Push to branch (`git push origin feature/amazing-feature`)
5. Open a Pull Request

## ğŸ“ License

This project is for educational and research purposes.

## âš ï¸ Disclaimer

This scraper is for educational purposes. Always respect Google Maps Terms of Service and implement appropriate rate limiting. The authors are not responsible for misuse of this tool.
